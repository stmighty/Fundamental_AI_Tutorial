{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# architecture of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Relative path to the image directory\n",
    "# './' refers to the current directory\n",
    "image_dir = os.path.join('.', 'image')\n",
    "\n",
    "# Construct the path to the image using os.path.join\n",
    "image_path = os.path.join(image_dir, 'CNN_architecture.jpg')\n",
    "\n",
    "# Reading an image in default mode\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was successfully loaded\n",
    "if image is None:\n",
    "    raise ValueError(\"Failed to load the image. The file may be corrupted or in an unsupported format.\")\n",
    "\n",
    "plt.axis('off')  # Command for hiding the axis\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we're going to cover\n",
    "\n",
    "We're going to apply the PyTorch Workflow we've been learning in the past couple of sections to computer vision.\n",
    "\n",
    "![a PyTorch workflow with a computer vision focus](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-pytorch-computer-vision-workflow.png)\n",
    "\n",
    "Specifically, we're going to cover:\n",
    "\n",
    "| **Topic** | **Contents** |\n",
    "| ----- | ----- |\n",
    "| **0. Computer vision libraries in PyTorch** | PyTorch has a bunch of built-in helpful computer vision libraries, let's check them out.  |\n",
    "| **1. Load data** | To practice computer vision, we'll start with some images of different pieces of clothing from [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). |\n",
    "| **2. Prepare data** | We've got some images, let's load them in with a [PyTorch `DataLoader`](https://pytorch.org/docs/stable/data.html) so we can use them with our training loop. |\n",
    "| **3. Model 0: Building a baseline model** | Here we'll create a multi-class classification model to learn patterns in the data, we'll also choose a **loss function**, **optimizer** and build a **training loop**. | \n",
    "| **4. Making predictions and evaluting model 0** | Let's make some predictions with our baseline model and evaluate them. |\n",
    "| **5. Setup device agnostic code for future models** | It's best practice to write device-agnostic code, so let's set it up. |\n",
    "| **6. Model 1: Adding non-linearity** | Experimenting is a large part of machine learning, let's try and improve upon our baseline model by adding non-linear layers. |\n",
    "| **7. Model 2: Convolutional Neural Network (CNN)** | Time to get computer vision specific and introduce the powerful convolutional neural network architecture. |\n",
    "| **8. Comparing our models** | We've built three different models, let's compare them. |\n",
    "| **9. Evaluating our best model** | Let's make some predictons on random images and evaluate our best model. |\n",
    "| **10. Making a confusion matrix** | A confusion matrix is a great way to evaluate a classification model, let's see how we can make one. |\n",
    "| **11. Saving and loading the best performing model** | Since we might want to use our model for later, let's save it and make sure it loads back in correctly. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Computer vision libraries in PyTorch # how is it different from pip install dataset?? huggingface dataset เอาเข้ามายังไงมันมีใน lib ??\n",
    "\n",
    "Before we get started writing code, let's talk about some PyTorch computer vision libraries you should be aware of.\n",
    "\n",
    "| PyTorch module | What does it do? |\n",
    "| ----- | ----- |\n",
    "| [`torchvision`](https://pytorch.org/vision/stable/index.html) | Contains datasets, model architectures and image transformations often used for computer vision problems. |\n",
    "| [`torchvision.datasets`](https://pytorch.org/vision/stable/datasets.html) | Here you'll find many example computer vision datasets for a range of problems from image classification, object detection, image captioning, video classification and more. It also contains [a series of base classes for making custom datasets](https://pytorch.org/vision/stable/datasets.html#base-classes-for-custom-datasets). |\n",
    "| [`torchvision.models`](https://pytorch.org/vision/stable/models.html) | This module contains well-performing and commonly used computer vision model architectures implemented in PyTorch, you can use these with your own problems. | \n",
    "| [`torchvision.transforms`](https://pytorch.org/vision/stable/transforms.html) | Often images need to be transformed (turned into numbers/processed/augmented) before being used with a model, common image transformations are found here. | \n",
    "| [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) | Base dataset class for PyTorch.  | \n",
    "| [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#module-torch.utils.data) | Creates a Python iterable over a dataset (created with `torch.utils.data.Dataset`). |\n",
    "\n",
    "> **Note:** The `torch.utils.data.Dataset` and `torch.utils.data.DataLoader` classes aren't only for computer vision in PyTorch, they are capable of dealing with many different types of data.\n",
    "\n",
    "Now we've covered some of the most important PyTorch computer vision libraries, let's import the relevant dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets                   # how is it different from !pip install datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "#matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#check version\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. getting dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use torchvision.transforms.ToTensor() because we want the data as a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup dataset\n",
    "from torchvision import datasets\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root = \"data\",   # where to download\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = torchvision.transforms.ToTensor(),     # how do we want to transforms the data      #Convert a PIL Image or ndarray to tensor and scale the values accordingly.     #https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html\n",
    "    target_transform = None  # how do we want to transforms the labels/targets\n",
    ")\n",
    "\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    "    target_transform = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = train_data.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See first training sample\n",
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"image shape: {image.shape} -> [chanel, height, width]\")\n",
    "print(f\"image label: {class_names[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 check input output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 visualize our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image, label = train_data[0]\n",
    "print(image.shape)\n",
    "print(label)\n",
    "print(image.squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.squeeze())\n",
    "plt.title(label)\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot more images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. prepare data loader\n",
    "\n",
    "Right now, our data is in the form of pytorch dataset\n",
    "\n",
    "Dataloader turns our dataset into a python iterable\n",
    "\n",
    "More specifically, we want to turn our data into batches (or mini-batches).\n",
    "\n",
    "    Why do this?\n",
    "\n",
    "Because it's more computationally efficient.\n",
    "\n",
    "In an ideal world you could do the forward pass and backward pass across all of your data at once.\n",
    "\n",
    "But once you start using really large datasets, unless you've got infinite computing power, it's easier to break them up into batches.\n",
    "\n",
    "It also gives your model more opportunities to improve.\n",
    "\n",
    "With mini-batches (small portions of the data), gradient descent is performed more often per epoch (once per mini-batch rather than once per epoch).\n",
    "\n",
    "What's a good batch size?\n",
    "\n",
    "32 is a good place to start for a fair amount of problems.\n",
    "\n",
    "But since this is a value you can set (a hyperparameter) you can try all different kinds of values, though generally powers of 2 are used most often (e.g. 32, 64, 128, 256, 512)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Dataloader -> https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset = test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True)\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    * Dataloader is batch of data. when we iterate through data loader, each iterate is a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out what's inside the training dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))             #example here https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels_batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build a simple baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a flatten layer\n",
    "flatten_model = nn.Flatten()\n",
    "\n",
    "#get a single sample\n",
    "x = train_features_batch[0]\n",
    "print(\"shape before flatten is\", x.shape)\n",
    "\n",
    "#Flatten the sample\n",
    "output = flatten_model(x)\n",
    "print(\"shape after flatten is\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FashionMNISTModelV0(nn.Module) :\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int) :\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(in_features=input_shape,\n",
    "                      out_features=hidden_units),\n",
    "            \n",
    "            nn.Linear(in_features=hidden_units,\n",
    "                      out_features=output_shape)\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        return self.layer_stack(x)\n",
    "    \n",
    "\n",
    "## same as \n",
    "'''\n",
    "class FashionMNISTModelV0(nn.Module) :\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int) :\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_0 = nn.Flatten()\n",
    "        self.layer_1 = nn.Linear(in_features=input_shape, out_features=hidden_units)\n",
    "        self.layer_2 = nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        return self.layer_2(self.layer_1(self.layer_0(x)))\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#setup model \n",
    "model_0 = FashionMNISTModelV0(\n",
    "    input_shape=784,   # from 28*28 image\n",
    "    hidden_units=15,\n",
    "    output_shape=len(class_names)\n",
    ")\n",
    "\n",
    "model_0.to(device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_x = torch.rand([1,1,28,28])\n",
    "print(model_0(dummy_x))\n",
    "print()\n",
    "\n",
    "\n",
    "dummy_x = torch.rand([1,28,28])\n",
    "print(model_0(dummy_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Setup loss, optimizer and evaluation metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path \n",
    "\n",
    "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "  print(\"helper_functions.py already exists, skipping download\")\n",
    "else:\n",
    "  print(\"Downloading helper_functions.py\")\n",
    "  # Note: you need the \"raw\" GitHub URL for this to work\n",
    "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "  with open(\"helper_functions.py\", \"wb\") as f:\n",
    "    f.write(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import accuracy metric\n",
    "from helper_functions import accuracy_fn # Note: could also use torchmetrics.Accuracy(task = 'multiclass', num_classes=len(class_names)).to(device)\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss() # this is also called \"criterion\"/\"cost function\" in some places\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 create a function to time our experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format). \n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Creating a training loop and training a model on batches of data (cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's step through it:\n",
    "\n",
    "1. Loop through epochs.\n",
    "2. Loop through training batches, perform training steps, calculate the train loss per batch.\n",
    "3. Loop through testing batches, perform testing steps, calculate the test loss per batch.\n",
    "4. Print out what's happening.\n",
    "5. Time it all (for fun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#set the seed\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "#set the number of epochs\n",
    "epoch = 10\n",
    "\n",
    "# create training and testing loop\n",
    "for epoch in tqdm(range(epoch)) :\n",
    "    print(\"Epoch:\", epoch)\n",
    "    \n",
    "    ### training\n",
    "    train_loss = 0\n",
    "    # loop through\n",
    "    for batch, (X, y) in enumerate(train_dataloader) :\n",
    "        model_0.train()\n",
    "        \n",
    "        #1. forward pass\n",
    "        y_pred = model_0(X)\n",
    "        \n",
    "        #2. calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        \n",
    "        #3. optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #4. loss backward\n",
    "        loss.backward()\n",
    "        \n",
    "        #5. optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        #print out\n",
    "        if batch % 400 == 0 :\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "            \n",
    "\n",
    "    # divide total train loss by length of train dataloader\n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    ### testing\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode() :\n",
    "        for x_test, y_test in test_dataloader :\n",
    "            #1. forward pass\n",
    "            test_pred = model_0(x_test)\n",
    "            \n",
    "            #2. calculate loss\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "            \n",
    "            #3. calculate accuracy\n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
    "        \n",
    "        #calculate the test loss\n",
    "        test_loss /= len(test_dataloader)\n",
    "        \n",
    "        #calculate test acc\n",
    "        test_acc /= len(test_dataloader)\n",
    "    \n",
    "    #print out\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
    "        \n",
    "# Calculate training time      \n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu, \n",
    "                                           end=train_time_end_on_cpu,\n",
    "                                           device=str(next(model_0.parameters()).device))\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#set the seed\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "#set epochs\n",
    "epochs = 3\n",
    "\n",
    "#create training loop\n",
    "for epoch in tqdm(range(epochs)) :\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "    \n",
    "    #training\n",
    "    train_loss = 0\n",
    "    #loop through batches\n",
    "    for batch, (X,y) in enumerate(train_dataloader) :\n",
    "        \n",
    "        \n",
    "        model_0.train()\n",
    "        #1. forward pass\n",
    "        y_pred = model_0(X)\n",
    "        \n",
    "        #2. calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        \n",
    "        #3. optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #4. loss backward\n",
    "        loss.backward()\n",
    "        \n",
    "        #5. optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print out how many samples have been seen\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "            \n",
    "    # (average loss per batch per epoch)\n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### testing\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode() :\n",
    "        for X, y in test_dataloader :\n",
    "            #1. forward pass\n",
    "            test_pred = model_0(X)\n",
    "            \n",
    "            #2. calculate loss\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            \n",
    "            #3. calculate accuracy\n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
    "            \n",
    "        #divide total test loss\n",
    "        test_loss /= len(test_dataloader)\n",
    "        \n",
    "        #divide total accuracy\n",
    "        test_acc /= len(test_dataloader) \n",
    "        \n",
    "    ## Print out what's happening\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "# Calculate training time      \n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu, \n",
    "                                           end=train_time_end_on_cpu,\n",
    "                                           device=str(next(model_0.parameters()).device))\n",
    "                                           \n",
    "\n",
    "                                           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 make predictions and get Model0 result (cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module, \n",
    "               data_loader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               accuracy_fn):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Make predictions with the model\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            # Accumulate the loss and accuracy values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, \n",
    "                                y_pred=y_pred.argmax(dim=1)) # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
    "        \n",
    "        # Scale loss and acc to find the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "        \n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "# Calculate model 0 results on test dataset\n",
    "model_0_results = eval_model(model=model_0, data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn, accuracy_fn=accuracy_fn\n",
    ")\n",
    "model_0_results\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn) :\n",
    "    \"\"\"\n",
    "    Returns a dictionary containing the results of model prediction on data_loader.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): model \n",
    "        data_loader (torch.utils.data.DataLoader): target dataset\n",
    "        loss_fn (torch.nn.Module): loss function\n",
    "        accuracy_fn (_type_): accuracy\n",
    "\n",
    "    Returns:\n",
    "        (dict) : Results\n",
    "    \"\"\"\n",
    "    \n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode() :\n",
    "        for X, y in data_loader :\n",
    "            \n",
    "            #1. make prediction\n",
    "            y_pred = model_0(X)\n",
    "            \n",
    "            #2. loss and accuracy\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true = y, y_pred = y_pred.argmax(dim=1))\n",
    "            \n",
    "        # average\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "    \n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "    \n",
    "    \n",
    "# Calculate model 0 results on test dataset\n",
    "model_0_results = eval_model(model=model_0, data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn, accuracy_fn=accuracy_fn\n",
    ")\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Setup device agnostic-code (for using a GPU if there is one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device agnostic code\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model 1: Building a better model with non-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FashionMNISTModelV1(nn.Module) :\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int) :\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(in_features=input_shape,\n",
    "                      out_features=hidden_units),\n",
    "            \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(in_features=hidden_units,\n",
    "                      out_features=output_shape),\n",
    "            \n",
    "            nn.ReLU()\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#setup model \n",
    "model_1 = FashionMNISTModelV1(\n",
    "    input_shape=784,   # from 28*28 image\n",
    "    hidden_units=15,\n",
    "    output_shape=len(class_names)\n",
    ")\n",
    "\n",
    "model_1.to(device)\n",
    "model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Setup loss, optimizer and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(), \n",
    "                            lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Functionizing training and test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#set the seed\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "#set the number of epochs\n",
    "epoch = 10\n",
    "\n",
    "# create training and testing loop\n",
    "for epoch in tqdm(range(epoch)) :\n",
    "    print(\"Epoch:\", epoch)\n",
    "    \n",
    "    ### training\n",
    "    train_loss = 0\n",
    "    # loop through\n",
    "    for batch, (X, y) in enumerate(train_dataloader) :\n",
    "        model_1.train()\n",
    "        \n",
    "        #1. forward pass\n",
    "        y_pred = model_1(X)\n",
    "        \n",
    "        #2. calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        \n",
    "        #3. optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #4. loss backward\n",
    "        loss.backward()\n",
    "        \n",
    "        #5. optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        #print out\n",
    "        if batch % 400 == 0 :\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "            \n",
    "\n",
    "    # divide total train loss by length of train dataloader\n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    ### testing\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_1.eval()\n",
    "    with torch.inference_mode() :\n",
    "        for x_test, y_test in test_dataloader :\n",
    "            #1. forward pass\n",
    "            test_pred = model_1(x_test)\n",
    "            \n",
    "            #2. calculate loss\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "            \n",
    "            #3. calculate accuracy\n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
    "        \n",
    "        #calculate the test loss\n",
    "        test_loss /= len(test_dataloader)\n",
    "        \n",
    "        #calculate test acc\n",
    "        test_acc /= len(test_dataloader)\n",
    "    \n",
    "    #print out\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
    "\n",
    "'''\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device) :\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader) :\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        #1. forward pass\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        #2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        accuracy = accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1))\n",
    "        \n",
    "        train_loss += loss\n",
    "        train_acc += accuracy\n",
    "        \n",
    "        #3. optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #4. loss backward\n",
    "        loss.backward()\n",
    "        \n",
    "        #5. optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device) :\n",
    "    \n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode() :\n",
    "        for X, y in data_loader :\n",
    "            \n",
    "            #send data to gpu\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            #1. forward pass\n",
    "            test_pred = model(X)\n",
    "            \n",
    "            #2. calculate loss and accuracy\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            accuracy = accuracy_fn(y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1))\n",
    "            \n",
    "            test_loss += loss\n",
    "            test_acc += accuracy\n",
    "            \n",
    "            \n",
    "        #average\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Send data to GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval() # put model in eval mode\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode(): \n",
    "        for X, y in data_loader:\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "            \n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
    "            )\n",
    "        \n",
    "        #average\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)) :\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    \n",
    "    train_step(data_loader=train_dataloader,\n",
    "               model=model_1,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accuracy_fn=accuracy_fn)\n",
    "\n",
    "    test_step(data_loader=test_dataloader,\n",
    "              model=model_1,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy_fn=accuracy_fn)\n",
    "\n",
    "# Calculate training time      \n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start_on_cpu, \n",
    "                                           end=train_time_end_on_cpu,\n",
    "                                           device=str(next(model_1.parameters()).device))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module, \n",
    "               data_loader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    \"\"\"Evaluate a given model on a given dataset\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): model\n",
    "        data_loader (torch.utils.data.DataLoader): target data\n",
    "        loss_fn (torch.nn.Module): loss function\n",
    "        accuracy_fn (_type_): accuracy\n",
    "        device (torch.device, optional): device\n",
    "        \n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode() :\n",
    "        for X, y in data_loader :\n",
    "            \n",
    "            #send data to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            loss = loss_fn(y_pred, y)\n",
    "            accuracy = accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "            eval_loss += loss\n",
    "            eval_acc += accuracy\n",
    "            \n",
    "        #average\n",
    "        eval_loss /= len(data_loader)\n",
    "        eval_acc /= len(data_loader)\n",
    "        \n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": eval_loss.item(),\n",
    "            \"model_acc\": eval_acc}\n",
    "            \n",
    "    \n",
    "# Calculate model 1 results with device-agnostic code \n",
    "model_1_results = eval_model(model=model_1, data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn, accuracy_fn=accuracy_fn,\n",
    "    device=device\n",
    ")\n",
    "model_1_results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model2 : CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN model we're going to be using is known as TinyVGG from the [CNN Explainer](https://poloclub.github.io/cnn-explainer/) website.\n",
    "\n",
    "It follows the typical structure of a convolutional neural network:\n",
    "\n",
    "`Input layer -> [Convolutional layer -> activation layer -> pooling layer] -> Output layer`\n",
    "\n",
    "Where the contents of `[Convolutional layer -> activation layer -> pooling layer]` can be upscaled and repeated multiple times, depending on requirements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's now build a CNN that replicates the model on the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
    "\n",
    "![TinyVGG architecture, as setup by CNN explainer website](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-cnn-explainer-model.png)\n",
    "\n",
    "To do so, we'll leverage the [`nn.Conv2d()`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) and [`nn.MaxPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) layers from `torch.nn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ** what does CNN (and most of neural network) do -> compress the input into some representation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create a CNN\n",
    "class FashionMNISTModelV2(nn.Module) :\n",
    "    \"\"\"\n",
    "    Model architecture that replicates the TinyVGG\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) :\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,                  #nn.Conv2d for data with 2d (image)\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,                  #nn.Conv2d for data with 2d (image)\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units *7 *7,          # *you need to calculate the last layer size \n",
    "                      out_features = output_shape)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "torch.manual_seed(42)\n",
    "model_2 = FashionMNISTModelV2(input_shape=1, \n",
    "    hidden_units=10, \n",
    "    output_shape=len(class_names)).to(device)\n",
    "model_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_2 = FashionMNISTModelV2(input_shape=1,\n",
    "                              hidden_units=15,\n",
    "                              output_shape=len(class_names))\n",
    "model_2.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 flatten and unsqueeze (you might read 7.1 and 7.2 first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_image_tensor = torch.rand(size=(10,7,7))\n",
    "flatten_layer = nn.Flatten()\n",
    "\n",
    "print(\"rand_image_tensor shape                             :\", rand_image_tensor.shape)\n",
    "print(\"rand_image_tensor.unsqueeze(0) shape                :\", rand_image_tensor.unsqueeze(0).shape)\n",
    "print(\"flatten_layer_rand_image_tensor shape               :\", flatten_layer(rand_image_tensor).shape)\n",
    "print(\"flatten_layer(rand_image_tensor.unsqueeze(0)) shape :\", flatten_layer(rand_image_tensor.unsqueeze(0)).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from how does nn.Flatten() work -> https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html\n",
    "we need to unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_image_tensor = torch.rand(size=(1,28,28))\n",
    "model_2(rand_image_tensor.unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 stepping through nn.Conv2d() and nn.ReLU()\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "#create a batch of images\n",
    "batch_images = torch.rand(size=(32,3,64,64))\n",
    "test_image = batch_images[0]\n",
    "\n",
    "print(\"Single image shape:\", test_image.shape)\n",
    "print(\"batch images shape:\", batch_images.shape)\n",
    "#print(f\"Test image:\\n {test_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# craete a single conv2d\n",
    "\n",
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=10,\n",
    "                       kernel_size=(3,3),\n",
    "                       stride=1,\n",
    "                       padding=0)\n",
    "\n",
    "conv_output_single_image = conv_layer(test_image)\n",
    "print(\"conv output of a single image shape  :\", conv_output_single_image.shape)\n",
    "#print(conv_output)\n",
    "\n",
    "\n",
    "#also works on batch of image\n",
    "conv_output_batch_images = conv_layer(batch_images)\n",
    "print(\"conv output of batch images shape    :\", conv_output_batch_images.shape)\n",
    "\n",
    "\n",
    "\n",
    "relu_layer = nn.ReLU()  # Define the ReLU layer\n",
    "\n",
    "relu_output_single_image = relu_layer(conv_output_single_image)  # Apply ReLU using nn.ReLU\n",
    "print(\"relu output of a single image shape  :\", relu_output_single_image.shape)\n",
    "# print(nn.ReLU(conv_output))  -> #The line print(nn.ReLU(conv_output)) does not work as intended because nn.ReLU is a class that needs to be instantiated before being applied to a tensor. Additionally, even if instantiated correctly, nn.ReLU does not directly operate on the tensor when passed as a parameter to its constructor. Instead, you need to create an instance of nn.ReLU and then call it as a function, passing the tensor as an argument.\n",
    "\n",
    "relu_output_batch_images = relu_layer(conv_output_batch_images)\n",
    "print(\"relu output of a batch images shape  :\", relu_output_batch_images.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 stepping through MAXPOOL2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "single_image_through_conv = conv_layer(test_image)\n",
    "print(\"single_image_through_conv shape               :\", single_image_through_conv.shape)\n",
    "\n",
    "single_image_through_conv_and_max_pool = max_pool_layer(single_image_through_conv)\n",
    "print(\"single_image_through_conv_and_max_pool shape  :\", single_image_through_conv_and_max_pool.shape)\n",
    "\n",
    "\n",
    "batch_images_through_conv = conv_layer(batch_images)\n",
    "print(\"batch_images_through_conv shape               :\", batch_images_through_conv.shape)\n",
    "\n",
    "batch_images_through_conv_and_max_pool = max_pool_layer(batch_images_through_conv)\n",
    "print(\"batch_images_through_conv_and_max_pool shape  :\", batch_images_through_conv_and_max_pool.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Setup a loss function and optimizer for model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(), \n",
    "                            lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Training and testing model_2 using our training and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_2.parameters(), \n",
    "                             lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** มาอ่าน\n",
    "1. optimizer = torch.optim.SGD(params=model_2.parameters(), \n",
    "                             lr=0.1)   ต้องใช้ model_2\n",
    "2. .to(device) -> Device Mismatch: When you call dummy_x.to(device), it returns a new tensor that has been moved to the specified device, but it doesn’t change the original dummy_x tensor. You need to either reassign dummy_x to this new tensor or do the operation inline when you pass it to the model.\n",
    "\n",
    "3. model.train(), model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#set the seed\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "#set the number of epochs\n",
    "epoch = 10\n",
    "\n",
    "# create training and testing loop\n",
    "for epoch in tqdm(range(epoch)) :\n",
    "    print(\"Epoch:\", epoch)\n",
    "    \n",
    "    ### training\n",
    "    train_loss = 0\n",
    "    # loop through\n",
    "    for batch, (X, y) in enumerate(train_dataloader) :\n",
    "        model_2.train()\n",
    "        \n",
    "        #1. forward pass\n",
    "        y_pred = model_2(X)\n",
    "        \n",
    "        #2. calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        \n",
    "        #3. optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #4. loss backward\n",
    "        loss.backward()\n",
    "        \n",
    "        #5. optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        #print out\n",
    "        if batch % 400 == 0 :\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "            \n",
    "\n",
    "    # divide total train loss by length of train dataloader\n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    ### testing\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_2.eval()\n",
    "    with torch.inference_mode() :\n",
    "        for x_test, y_test in test_dataloader :\n",
    "            #1. forward pass\n",
    "            test_pred = model_2(x_test)\n",
    "            \n",
    "            #2. calculate loss\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "            \n",
    "            #3. calculate accuracy\n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
    "        \n",
    "        #calculate the test loss\n",
    "        test_loss /= len(test_dataloader)\n",
    "        \n",
    "        #calculate test acc\n",
    "        test_acc /= len(test_dataloader)\n",
    "    \n",
    "    #print out\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
    "        \n",
    "# Calculate training time      \n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu, \n",
    "                                           end=train_time_end_on_cpu,\n",
    "                                           device=str(next(model_2.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
